
<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">

    <head>

        
        <meta charset="UTF-8" />

        
        <meta name="viewport" content="width=device-width, initial-scale=1"/>

                
        <title> 
               
        </title>
        
        
            <link href="https://example.com/index.xml" rel="alternate" type="application/rss+xml" title="Kiss&#39;Em!" />
        

        
        <link rel="stylesheet" href="/css/style.css"/>

        
        
            <link rel='stylesheet' href='https://example.com/css/custom.css'>
        
        
    </head>

    <body>



<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://example.com">
          <h1 id="nav-heading" class="title is-4">Kiss&#39;Em!</h1>
        </a>
      </div>
      <div class="nav-right">
        
        
        <nav id="nav-items" class="nav-item level is-mobile">
          <a class="level-item" aria-label="about" href='/about'
           rel='noopener'>
            <span class="icon">
              <i class>

<svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12" y2="8"></line>
    
  </svg></i>
            </span>
          </a>
          <a class="level-item" aria-label="email" href='mailto:info@pavel-pi.de'
           target='_blank'  rel='noopener'>
            <span class="icon">
              <i class>

<svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
            </span>
          </a>
          <a class="level-item" aria-label="github" href='https://github.com/pavel-pi'
           target='_blank'  rel='noopener'>
            <span class="icon">
              <i class>

<svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
            </span>
          </a>
          <a class="level-item" aria-label="twitter" href='https://twitter.com/@_pavel_pi_'
           target='_blank'  rel='noopener'>
            <span class="icon">
              <i class>

<svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
    
  </svg></i>
            </span>
          </a>
          <a class="level-item" aria-label="rss" href='/index.xml'
           target='_blank'  rel='noopener'>
            <span class="icon">
              <i class>

<svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle>
    
  </svg></i>
            </span>
          </a></nav>
        
      
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
</section>

<section class="section">
    
    <div class="container">
    
        
            
<div class="subtitle tags is-6 is-pulled-right">
    
</div>





<h1 class="title"></h1>

<div class="content">

    
    <h2 id="nginx实现tomcat集群负载均衡">Nginx实现Tomcat集群负载均衡</h2>
<h3 id="1负载均衡配置">1、负载均衡配置</h3>
<p>在nginx的配置文件加入负载均衡组:upstream，定义一个上游服务器集群，关于负载均衡的权重，有一系统的相关设置。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">upstream backend {
# ip_hash;
server s1.barretlee.com;
server s2.barretlee.com;
}
server {
location / {
proxy_pass http://backend;
}
}
</code></pre></div><h3 id="2负载均衡的模式">2、负载均衡的模式</h3>
<p>内置负载均衡策略</p>
<h4 id="--轮询默认">- 轮询（默认）</h4>
<p>相同的权重，当其中一个挂掉的时候，默认会请求其他的机器</p>
<h4 id="--span-data-typecolor-stylecolorrgb79-79-79span-data-typebackground-stylebackground-colorrgb255-255-255weight--spanspan">- <!-- raw HTML omitted --><!-- raw HTML omitted -->weight  <!-- raw HTML omitted --><!-- raw HTML omitted --></h4>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->默认为1，将请求平均分配给每台server<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">upstream tomcats {
    server 192.168.0.100:8080 weight=2;  # 2/6次
    server 192.168.0.101:8080 weight=3;  # 3/6次
    server 192.168.0.102:8080 weight=1;  # 1/6次
</code></pre></div><h4 id="down-down-表示单前的server暂时不参与负载backup-其它所有的非backup机器down或者忙的时候请求backup机器">down; (down 表示单前的server暂时不参与负载)，backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">upstream tomcats {
    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;

    server 192.168.0.101:8080 down;

    server 192.168.0.102:8080 backup;
}
</code></pre></div><h4 id="max_fails-允许请求失败的次数默认为1当超过最大次数时返回fail_timeoutmax_fails次失败后暂停的时间">max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回。fail_timeout:max_fails次失败后，暂停的时间</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">upstream tomcats {
    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;
    server 192.168.0.101:8080 weight=3;
    server 192.168.0.102:8080 weight=1;
}
</code></pre></div><h4 id="max_conns">max_conns</h4>
<p>限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为0，表示不限制。注意：1.5.9之后的版本才有这个配置</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">upstream tomcats {
    server 192.168.0.100:8080 max_conns=1000;
}
</code></pre></div><p>表示最多给100这台Server分配1000个请求，如果这台Server正在处理1000个请求，nginx将不会分配新的请求给到它。假如有一个请求处理完了，还剩下999个请求在处理，这时nginx也会将新的请求分配给它。</p>
<h4 id="span-data-typecolor-stylecolorrgb47-47-47span-data-typebackground-stylebackground-colorrgb255-255-255least_connspanspan"><!-- raw HTML omitted --><!-- raw HTML omitted -->least_conn<!-- raw HTML omitted --><!-- raw HTML omitted --></h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">
upstream tomcats {
server 192.168.0.100:8080;
server 192.168.0.101:8080;
least_conn;
}

</code></pre></div><h4 id="--ip_hash">- ip_hash</h4>
<p>上述方式存在一个问题就是说，在负载均衡系统中，假如用户在某台服务器上登录了，那么该用户第二次请求的时候，因为我们是负载均衡系统，每次请求都会重新定位到服务器集群中的某一个，那么__*已经登录某一个服务器的用户再重新定位到另一个服务器，其登录信息将会丢失，这样显然是不妥的*__。
我们可以采用__*ip_hash*__指令解决这个问题，如果客户已经访问了某个服务器，当用户再次访问时，会将该请求通过__*哈希算法，自动定位到该服务器*__。
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决__*session的问题*__。
需要注意的是：ip_hash要求nginx一定是最前端的服务器，否则nginx得不到正确ip，就不能根据ip作hash。譬如使用的是squid为最前端，那么nginx取ip时只能得到squid的服务器ip地址，用这个地址来作分流是肯定错乱的。</p>
<pre><code>upstream backserver {
    ip_hash;
    server 192.168.0.14:88;
    server 192.168.0.15:80;
}
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2019/png/84598/1550124302648-12930b2f-2758-4635-adfd-d12a80fddb9a.png" alt="image.png | left | 747x252" title=""></p>
<p>第三方负载均衡策略</p>
<h4 id="fair">fair</h4>
<p>根据服务器的响应时间来分配请求，响应时间短的优先分配，即负载压力小的优先会分配。
由于fair模块是第三方提供的，所以在编译nginx源码的时候，需要将fair添加到nginx模块中。
配置使用fair负载策略模块：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">
upstream tomcats {
    fair;
    server 192.168.0.100:8080;
    server 192.168.0.101:8080;
    server 192.168.0.102:8080;
}
</code></pre></div><p>由于采用fair负载策略，配置weigth参数改变负载权重将无效。</p>
<h4 id="url_hash">url_hash</h4>
<p>按请求url的hash结果来分配请求，使每个url定向到同一个后端服务器，服务器做缓存时比较有效。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain">
upstream tomcats {
    server 192.168.0.100:8080;
    server 192.168.0.101:8080;
    server 192.168.0.102:8080;
    hash $request_uri;
}

</code></pre></div><h3 id="nginx性能优化">Nginx性能优化</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-plain" data-lang="plain"># 这个控制Nginx运行的工作进程个数。大多数情况下，一个CPU核心跑一个工作进程能够工作得很好。可以将该指令设为auto来达到与CPU核心数匹配的工作进程数
worker_processes  auto;
events {
    #这个表示每个工作进程同时能够处理的最大连接数。默认值是512，但是大多数系统能处理更大的值。这个值该设为多少取决于服务器硬件配置以及流量的特性，可以通过测试来发现。
    worker_connections  51200;
}
http {
# Sendfile是一个操作系统特性，可以在Nginx上启用。它通过在内核中从一个文件描述符向另一个文件描述符复制数据，往往能达到零拷贝，因而可以提供更快的TCP数据传输。
sendfile        on;
持久连接可以减少打开和关闭连接所需要的CPU和网络开销，因而对性能有重大影响。表示空闲持久连接保持打开状态多长时间
keepalive_timeout  65;
# 开启压缩，压缩响应可以大大减小响应的大小，减少带宽占用
gzip  on;
}
</code></pre></div><h3 id="性能测试">性能测试</h3>
<h4 id="测试方式">测试方式</h4>
<p>测试工具jmeter
测试结果说明</p>
<ul>
<li>Label：每个 JMeter 的 element （例如 HTTP Request ）都有一个 Name 属性，这里显示的就是 Name 属性的值</li>
<li>Samples：表示你这次测试中一共发出了多少个请求，我的测试计划模拟 10 个用户，每个用户迭代 10 次，因此这里显示 100</li>
<li>Average：平均响应时间 —— 默认情况下是单个 Request 的平均响应时间，当使用了 Transaction Controller 时，也可以以 Transaction 为单位显示平均响应时间</li>
<li>Median：中位数，也就是 50 ％用户的响应时间</li>
<li>90% Line： 90 ％用户的响应时间</li>
<li>Min： 最小响应时间</li>
<li>Max： 最大响应时间</li>
<li>Error%：本次测试中出现错误的请求的数量 / 请求的总数</li>
<li>Throughput：吞吐量 —— 默认情况下表示每秒完成的请求数（ Request per Second ），当使用了 Transaction Controller 时，也可以表示类似 LoadRunner 的 Transaction per Second 数</li>
<li>KB/Sec：每秒从服务器端接收到的数据量，相当于 LoadRunner 中的 Throughput/Sec
采取两台服务器进行负载均衡，设置了三个线程组，每个线程组100次请求
tomcat1（8.0）</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/84598/1546783614412-b07aca4f-3639-46ba-8ba0-d14178c38574.png" alt="image.png | left | 827x221" title=""></p>
<p>tomcat2（8.5）</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/84598/1546783640108-f13d747c-a3aa-4dd1-9473-0bf859ef9dca.png" alt="image.png | left | 827x209" title=""></p>
<p>nginx</p>
<p><img src="https://cdn.nlark.com/yuque/0/2019/png/84598/1546783683698-316466c2-35d6-4423-9ed8-150dd0018a9f.png" alt="image.png | left | 827x205" title=""></p>
<h4 id="结果分析">结果分析</h4>
<p>三组测试结果 因为是同样的网络环境，接受数据基本一致；
tomcat8.5的最大响应时间低于8.0
nginx的负载均衡的最大响应时间低于单独的tomcat
但是三组测试的吞吐量基本一致</p>


    
    
        <div class="related">

</div>
    

</div>


        

    </div>

</section>



<section class="section">
  <div class="container has-text-centered">
    <p>© <a href="https://github.com/pavel-pi">Pavel Pi</a> 2020</p>
    
      <p>Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/pavel-pi/kiss-em">Kiss'Em</a>.</p>
    
  </div>
</section>

</body>
</html>

